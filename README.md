# har
Scope of the Project-

Use the DataSet for Human Avtivity Recognition already available-
https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones

Build a Deep Neural Network with different models-
Use the training dataset to train the model
Use the test dataset to evaluate the model
See which model performs the best

Add visualization, accuracy/loss graphs and confusion matrix

Capture some data using sensor or SmartPhone for some of the activities.
Need to determine how to get that data and represent it exactly what the HAR dataset corresponds to
Test that data against the model

If successful with the above step, we can capture some other activity data and retrain the model
Evaluate the model with some test data

How can we save this model to the sensor itself (Research on Transfer Learning, optimizing the model and saving it)

Some other alternatives - Use OpenCV, capture the data and save and test it and display the activity performed.

Look at the HAR with Gestures (Proposal from Shreya) - Controlling a computer with Gestures using the Myoband sensor
